{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC8810_HW1-3 Number of parameters v.s. Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tf.__version__\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-622b25771082>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/kzhai/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/kzhai/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/kzhai/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/kzhai/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/kzhai/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Training Dataset Size: 55000\n",
      "Validation Dataset Size: 5000\n",
      "Testing Dataset Size: 10000\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True);\n",
    "\n",
    "train_num = data.train.num_examples\n",
    "valid_num = data.validation.num_examples\n",
    "test_num = data.test.num_examples\n",
    "img_flatten = 784\n",
    "img_size = 28\n",
    "num_classes = 10\n",
    "print(\"Training Dataset Size:\",train_num)\n",
    "print(\"Validation Dataset Size:\",valid_num)\n",
    "print(\"Testing Dataset Size:\",test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_count():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        #print(variable)\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        #print(\"parameter num:\",variable_parameters)\n",
    "        total_parameters += variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-613e0504822e>:5: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From <ipython-input-4-613e0504822e>:7: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/kzhai/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-613e0504822e>:8: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-613e0504822e>:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-613e0504822e>:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-613e0504822e>:16: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "m1 =  13972\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=2,kernel_size=1,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=2,kernel_size=1,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m1 = parameter_count()\n",
    "print('m1 = ', m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.319825, Training Accuracy:  92.2%, Test Loss: 0.296465, Test Accuracy:  90.6%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2 =  66345\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=2,kernel_size=1,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=1)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=3,kernel_size=2,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m2 = parameter_count()\n",
    "print('m2 = ', m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.152705, Training Accuracy:  98.4%, Test Loss: 0.110608, Test Accuracy:  96.6%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m3 =  26552\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=2,kernel_size=2,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=4,kernel_size=2,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m3 = parameter_count()\n",
    "print('m3 = ', m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.112694, Training Accuracy:  95.3%, Test Loss: 0.120061, Test Accuracy:  96.3%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m4 =  26694\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=4,kernel_size=3,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=4,kernel_size=3,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m4 = parameter_count()\n",
    "print('m4 = ', m4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.17711, Training Accuracy:  93.8%, Test Loss: 0.0962295, Test Accuracy:  97.0%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m5 =  52182\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=4,kernel_size=4,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=8,kernel_size=4,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m5 = parameter_count()\n",
    "print('m5 = ', m5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.0632565, Training Accuracy:  96.9%, Test Loss: 0.0598045, Test Accuracy:  98.1%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m6 =  52258\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=8,kernel_size=3,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=8,kernel_size=3,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m6 = parameter_count()\n",
    "print('m6 = ', m6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.0542464, Training Accuracy:  98.4%, Test Loss: 0.054493, Test Accuracy:  98.4%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m7 =  79302\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=8,kernel_size=5,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=12,kernel_size=5,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m7 = parameter_count()\n",
    "print('m7 = ', m7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.044501, Training Accuracy:  98.4%, Test Loss: 0.0520916, Test Accuracy:  98.4%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 8 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m8 =  105194\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=8,kernel_size=5,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=16,kernel_size=5,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m8 = parameter_count()\n",
    "print('m8 = ', m8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.00378866, Training Accuracy: 100.0%, Test Loss: 0.0508564, Test Accuracy:  98.3%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 9 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m9 =  66908\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=10,kernel_size=5,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=10,kernel_size=5,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m9 = parameter_count()\n",
    "print('m9 = ', m9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.0711637, Training Accuracy:  96.9%, Test Loss: 0.0589481, Test Accuracy:  98.1%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 10 Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m10 =  228042\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape = [None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=16,kernel_size=7,padding=\"SAME\",activation=tf.nn.leaky_relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=32,kernel_size=7,padding=\"same\",activation=tf.nn.leaky_relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2)\n",
    "\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.leaky_relu)\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "softmax = tf.nn.softmax(logits=logits)\n",
    "pred_op = tf.argmax(softmax,dimension=1)\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "m10 = parameter_count()\n",
    "print('m10 = ', m10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      0, Training Loss: 0.0252854, Training Accuracy:  98.4%, Test Loss: 0.0689441, Test Accuracy:  98.0%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x: x_batch, y: y_true_batch})\n",
    "\n",
    "\n",
    "    train_loss, train_acc = sess.run([loss,acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = sess.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    # Message for printing.\n",
    "    msg = \"Iteration: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    # Print it.\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5QeVZnv8e/PJoFWSAKkB8kFEiByjJJD8AUd8eAFJEEFMhzkJDMcUVFERYbDMsdkyULMOMMloyAOM4KKjCgTw8UYdTwtA+gaHZF0CCQk2tKJQNKgBEK4aAu5POeP2g2VTnXS3el6L92/z1q1+q29d9X7vJXO+3TtXbVLEYGZmVlPr6p1AGZmVp+cIMzMrJAThJmZFXKCMDOzQk4QZmZWyAnCzMwKOUGY7QFJkySFpL360PaDkn6+p/sxqxYnCBs2JD0i6SVJY3uUr0hfzpNqE5lZfXKCsOHmd8Cc7hVJRwGvrl04ZvXLCcKGm5uBD+TWzwG+lW8gabSkb0naKOlRSZdIelWqa5L0j5KekrQOeG/Btt+Q9ISkTklfkNTU3yAljZO0VNImSR2SPpqrO05Sm6TnJP1B0pdS+T6Svi3paUmbJS2TdFB/39usmxOEDTf3AqMkvT59cc8Gvt2jzVeA0cBhwNvJEsqHUt1HgfcB04EKcGaPbW8CtgJHpDYnAx8ZQJyLgA3AuPQe/yDpXanuy8CXI2IUcDiwOJWfk+KeCBwInA90DeC9zQAnCBueus8i3g38GujsrsgljfkR8XxEPAJ8EfjfqclZwDURsT4iNgGX57Y9CHgPcFFE/DEingSuTvvrM0kTgeOBz0TEnyPiAeDrvHLmswU4QtLYiHghIu7NlR8IHBER2yJieUQ815/3NstzgrDh6Gbgr4EP0qN7CRgLjAAezZU9CoxPr8cB63vUdTs0bftE6uLZDFwP/EU/4xsHbIqI53uJ4VzgdcBvUjfS+3KfqxVYJOlxSVdJGtHP9zZ7mROEDTsR8SjZYPV7gDt6VD9F9pf4obmyQ3jlLOMJsi6cfF239cCLwNiIGJOWURHxhn6G+DhwgKT9imKIiIcjYg5Z4rkSuE3SayJiS0R8PiKmAm8l6wr7AGYD5ARhw9W5wLsi4o/5wojYRtan//eS9pN0KHAxr4xTLAYulDRB0v7AvNy2TwA/Ab4oaZSkV0k6XNLb+xNYRKwH/gu4PA08T0vxfhtA0tmSWiJiO7A5bbZd0jslHZW6yZ4jS3Tb+/PeZnlOEDYsRcTaiGjrpfpTwB+BdcDPgVuAG1Pd18i6cR4E7mfnM5APACOBNcAzwG3AwQMIcQ4wiexs4nvA5yLiP1LdTGC1pBfIBqxnR0QX8Nr0fs+Rja38jKzbyWxA5AcGmZlZEZ9BmJlZIScIMzMrVGqCkDRTUnu6E3ReQf35klZJekDSzyVNTeWTJHWl8gckfbXMOM3MbGeljUGkKyl+S3Yz0gZgGTAnItbk2ozqvpFH0mnAJyJiZpo07YcR8cZSgjMzs90qc2rh44COiFgHIGkRcDrZ1R0A9LjL8zXAgLPV2LFjY9KkSQPd3MxsWFq+fPlTEdFSVFdmghjPjnecbgDe3LORpE+SXWc+EnhXrmqypBVkl+xdEhH/WbDtecB5AIcccghtbb1dtWhmZkUkPdpbXc0HqSPiuog4HPgMcEkqfgI4JCKmkyWPWySNKtj2hoioRESlpaUwAZqZ2QCVmSA62XFKggnkJkUrsAiYBRARL0bE0+n1cmAt2dwzZmZWJWUmiGXAFEmTJY0km9Fyab6BpCm51fcCD6fylu459CUdBkwhu6vVzMyqpLQxiIjYKukCsmkJmoAbI2K1pAVAW0QsBS6QdBLZnDHPkM1nD3ACsEBS91wy56eplc3MrEqGzFQblUolPEhtZtY/kpZHRKWoruaD1GZmVp+cIMzMrJAThJmZFXKCMDOzQk4QZmZWyAnCzMwKOUGYmVkhJwgzMytU5myuDWfJik4Wtrbz+OYuxo1pZu6MI5k1fXytwzIzqwkniGTJik7m37GKri3bAOjc3MX8O1YBOEmY2bDkLqZkYWv7y8mhW9eWbSxsba9RRGZmteUEkTy+uatf5WZmQ50TRDJuTHO/ys3MhjoniGTujCNpHtG0Q1nziCbmzjiyRhGZmdWWB6mT7oFoX8VkZpZxgsiZNX28E4KZWeIuJjMzK+QEYWZmhZwgzMysUKkJQtJMSe2SOiTNK6g/X9IqSQ9I+rmkqbm6+Wm7dkkzyozTzMx2VlqCkNQEXAecAkwF5uQTQHJLRBwVEUcDVwFfSttOBWYDbwBmAv+c9mdmZlVS5hnEcUBHRKyLiJeARcDp+QYR8Vxu9TVApNenA4si4sWI+B3QkfZnZmZVUuZlruOB9bn1DcCbezaS9EngYmAk8K7ctvf22Lb8609XLoa7FsCzG2D0BDjxUph2Vulva2ZWj2o+SB0R10XE4cBngEv6s62k8yS1SWrbuHHjngWycjH84EJ4dj0Q2c8fXJiVm5kNQ2UmiE5gYm59QirrzSJgVn+2jYgbIqISEZWWlpY9i/auBbClx8R8W7qycjOzYajMBLEMmCJpsqSRZIPOS/MNJE3Jrb4XeDi9XgrMlrS3pMnAFOC+EmPNupX6U25mNsSVNgYREVslXQC0Ak3AjRGxWtICoC0ilgIXSDoJ2AI8A5yTtl0taTGwBtgKfDIithW+0WAZPSF1LxWUm5kNQ4qI3bdqAJVKJdra2ga+g+4xiHw304hmOPVaD1Sb2ZAlaXlEVIrqaj5IXTemnZUlg9ETAWU/nRzMbBjzbK55085yQjAzS3wGYWZmhZwgzMyskBOEmZkVcoIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkVcoIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMysUKkJQtJMSe2SOiTNK6i/WNIaSSsl3SXp0FzdNkkPpGVpmXGamdnOSnsmtaQm4Drg3cAGYJmkpRGxJtdsBVCJiD9J+jhwFfC/Ul1XRBxdVnxmZrZrZZ5BHAd0RMS6iHgJWAScnm8QEfdExJ/S6r3AhBLjMTOzfigzQYwH1ufWN6Sy3pwL/Di3vo+kNkn3SppVtIGk81Kbto0bN+55xGZm9rLSupj6Q9LZQAV4e6740IjolHQYcLekVRGxNr9dRNwA3ABQqVSiagGbmQ0DZZ5BdAITc+sTUtkOJJ0EfBY4LSJe7C6PiM70cx3wU2B6ibGamVkPZSaIZcAUSZMljQRmAztcjSRpOnA9WXJ4Mle+v6S90+uxwPFAfnDbzMxKVloXU0RslXQB0Ao0ATdGxGpJC4C2iFgKLAT2BW6VBPBYRJwGvB64XtJ2siR2RY+rn8zMrGSKGBpd95VKJdra2modhplZQ5G0PCIqRXW+k9rMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkVcoIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkVcoIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK+QEYWZmhUpNEJJmSmqX1CFpXkH9xZLWSFop6S5Jh+bqzpH0cFrOKTNOMzPbWWkJQlITcB1wCjAVmCNpao9mK4BKREwDbgOuStseAHwOeDNwHPA5SfuXFauZme2szDOI44COiFgXES8Bi4DT8w0i4p6I+FNavReYkF7PAO6MiE0R8QxwJzCzxFjNzKyHMhPEeGB9bn1DKuvNucCP+7OtpPMktUlq27hx4x6Ga2ZmeXUxSC3pbKACLOzPdhFxQ0RUIqLS0tJSTnBmZsNUmQmiE5iYW5+QynYg6STgs8BpEfFif7Y1M7PylJkglgFTJE2WNBKYDSzNN5A0HbieLDk8matqBU6WtH8anD45lZmZWZXsVdaOI2KrpAvIvtibgBsjYrWkBUBbRCwl61LaF7hVEsBjEXFaRGyS9HdkSQZgQURsKitWMzPbmSKi1jEMikqlEm1tbbUOw8ysoUhaHhGVorq6GKQ2M7P64wRhZmaFnCDMzKyQE4SZmRUq7Sqm4WrJik4Wtrbz+OYuxo1pZu6MI5k1fVc3kJuZ1ScniEG0ZEUn8+9YRdeWbQB0bu5i/h2rAJwkzKzhuItpEC1sbX85OXTr2rKNha3tNYrIzGzgnCAG0eObu/pVbmZWz/qUICQdLmnv9Podki6UNKbc0BrPuDHN/So3M6tnfT2DuB3YJukI4AayifRuKS2qBjV3xpE0j2jaoax5RBNzZxxZo4jMzAaur4PU29PcSn8FfCUiviJpRZmBNaLugWhfxWRmQ0FfE8QWSXOAc4BTU9mIckJqbLOmj3dCMLMhoa9dTB8C/hL4+4j4naTJwM3lhWVmZrXWpzOIiFgDXAiQns+wX0RcWWZgZmZWW329iumnkkZJOgC4H/iapC+VG5qZmdVSX7uYRkfEc8AZwLci4s3ASeWFZWZmtdbXBLGXpIOBs4AflhiPmZnVib4miAVkjw5dGxHLJB0GPFxeWGZmVmt9HaS+Fbg1t74O+J9lBWX1y7PVmg0ffR2kniDpe5KeTMvtkiaUHZzVl+7Zajs3dxG8MlvtkhWdtQ7NzErQ1y6mbwJLgXFp+UEq2yVJMyW1S+qQNK+g/gRJ90vaKunMHnXbJD2QlqV9jNNK5NlqzYaXvt5J3RIR+YRwk6SLdrWBpCbgOuDdwAZgmaSl6Z6Kbo8BHwQ+XbCLrog4uo/xWRV4tlqz4aWvZxBPSzpbUlNazgae3s02xwEdEbEuIl4CFgGn5xtExCMRsRLY3u/Ireo8W63Z8NLXBPFhsktcfw88AZxJ9pf/rowH1ufWN6SyvtpHUpukeyXNKmog6bzUpm3jxo392LUNhGerNRte+noV06PAafmy1MV0TRlBJYdGRGe6pPZuSasiYm2PuG4gm36cSqUSJcZieLZas+FmT55JfTG7ThCdZM+N6DYhlfVJRHSmn+sk/RSYDqzd5UZWOs9WazZ87MkjR7Wb+mXAFEmTJY0EZpNdCbX7HUv7555gNxY4Hliz663MzGww7UmC2GWXTkRsBS4guwP718DiiFgtaYGk0wAkHStpA/B+4HpJq9PmrwfaJD0I3ANc0ePqJzMzK5kiev+el/Q8xYlAQHNE7EkX1aCqVCrR1tZW6zDMzBqKpOURUSmq2+UXfETsV05IZmZW7/aki8nMzIYwJwgzMyvkBGFmZoWcIMzMrJAThJmZFXKCMDOzQk4QZmZWyAlisK1cDFe/ES4bk/1cubjWEZmZDUjd3Ak9JKxcDD+4ELakB+g8uz5bB5h2Vu3iMjMbAJ9BDKa7FrySHLpt6crKzcwajBPEYHp2Q//KzczqmBPEYBo9oX/lZmZ1zAliEC07/FN0xcgdyrpiJMsO/1SNIjIzGzgniEF00ZopfGbLR9iwfSzbQ2zYPpbPbPkIF62ZUuvQBo+v0jIbNnwV0yB6fHMXnbyNpS+9bYdybe7qZYsG46u0zIYVn0EMonFjmvtV3nB8lZbZsOIEMYjmzjiS5hFNO5Q1j2hi7owjaxTRIPNVWmbDiruYBtGs6eMBWNjazuObuxg3ppm5M458ubzhjZ6QdSsVlZvZkFNqgpA0E/gy0AR8PSKu6FF/AnANMA2YHRG35erOAS5Jq1+IiH8tM9bBMmv6+KGTEHo68dIdxyAARjRn5WY25JTWxSSpCbgOOAWYCsyRNLVHs8eADwK39Nj2AOBzwJuB44DPSdq/rFitj6adBadeC6MnAsp+nnqtB6jNhqgyzyCOAzoiYh2ApEXA6cCa7gYR8Uiq295j2xnAnRGxKdXfCcwE/q3EeK0vpp3lhGA2TJQ5SD0eyHdYb0hlZW9bW75PwMyGiIYepJZ0HnAewCGHHFLjaPB9AmY2pJR5BtEJTMytT0hlg7ZtRNwQEZWIqLS0tAw40EHj+wTMbAgpM0EsA6ZImixpJDAbWNrHbVuBkyXtnwanT05l9c33CZjZEFJagoiIrcAFZF/svwYWR8RqSQsknQYg6VhJG4D3A9dLWp223QT8HVmSWQYs6B6wrmuezdXMhhBFRK1jGBSVSiXa2tpqG0TPMQjI7hPwpaBmVqckLY+ISlGdp9oYTL5PwMyGkIa+iqku+T4BMxsifAZhZmaFnCDMzKyQE4SZmRVygjAzs0JOEGZmVsgJwszMCvkyV+uXJSs6h+4T88xsB04Q1mdLVnQy/45VdG3ZBkDn5i7m37EKwEnCrFpWLs4mAH12QzaNz4mXlnbvlbuYrM8Wtra/nBy6dW3ZxsLW9hpFZDbMdE/n8+x6IF55pEBJz51xgrA+e3xzV7/KzWyQVfmRAk4Q1mfjxjT3q9zMBlmVHyngBDHELVnRyfFX3M3keT/i+CvuZsmKvj6zaWdzZxxJ84imHcqaRzQxd8aRexqmmfVFlR8p4AQxhHUPKndu7iJ4ZVB5oEli1vTxXH7GUYwf04yA8WOaufyMozxAbVYtJ16aPUIgb0RzVl4CX8U0hC1sbefd237G/x25mHF6isdjLFdtPYuFrSMH/KU+q+kXzNp7AeyzAfaeAE2XAp691qwquq9WqtJVTE4QQ1jluTu5fMTXebVeAmCCnuKKEV9n/nMA7+r/Dns+EKn7CgrwFOdm1VLFRwq4i2kImz/y1peTQ7dX6yXmj7x1YDus8hUUZlZbThBD2EE81a/y3aryFRRmVltOEEPYSyNG9at8twbzCoqVi+HqN8JlY7KfJd3oY2YDV2qCkDRTUrukDknzCur3lvTdVP8rSZNS+SRJXZIeSMtXy4xzqOrasr1f5bs1WFdQVPlu0D7H5IRltoPSEoSkJuA64BRgKjBH0tQezc4FnomII4CrgStzdWsj4ui0nF9WnEPZqHi+l/IXBrbDaWfBqdfC6ImAsp+nXtv/AbN6G8uox4RlVgfKvIrpOKAjItYBSFoEnA6sybU5Hbgsvb4N+CdJKjGmYeVJtfBaNhaUj+W1A93pYFxBUW9jGbtKWL46y4axMruYxgPrc+sbUllhm4jYCjwLHJjqJktaIelnkv5H0RtIOk9Sm6S2jRt3/iIc7tYfM5euGLlDWVeMZP0xc2sUUVLlu0F3q94SllmdqNdB6ieAQyJiOnAxcIuknUZWI+KGiKhERKWlpaXqQda7Y0/7GA+96Qv8nha2h/g9LTz0pi9w7Gkfq21gJ17K1qZ9dija2rRPaXeD7la9JSyzOlFmF1MnMDG3PiGVFbXZIGkvYDTwdEQE8CJARCyXtBZ4HdBWYrxD0rGnfQxSQnhtWmptybbj+fmWj3ARixinp3k8DuSa7bN527bjmVWLgE68dMcbAKHU6QvMGkWZCWIZMEXSZLJEMBv46x5tlgLnAL8EzgTujoiQ1AJsiohtkg4DpgDrSozVqmhhazudL72V23jrDuW/bG2vzbxOVZ6+wKxRlJYgImKrpAuAVqAJuDEiVktaALRFxFLgG8DNkjqATWRJBOAEYIGkLcB24PyI2FRWrFZddflciSpOX2DWKEqdiyki/h349x5ll+Ze/xl4f8F2twO3lxmb1c64Mc10FiQDP1fCrL7U6yC1DWF+roRZY/BsrlZ13eMMC1vbeXxzF+PGNDN3xpF+roRZnXGCsJqYNX28E4JZnXMXk5mZFXKCMDOzQk4QZmZWyGMQZmYNZMmKzqpd4OEEYWbWIJas6GT+Havo2rINgM7NXcy/YxVAKUnCXUxmZg1iYWv7y8mhW9eWbSxsbS/l/ZwgzMwaRLWnqXGCMDNrEL1NR1PWNDVOEGZmDaLa09R4kNrMrEFUe5oaJwgzswZSzWlq3MVkZmaFnCDMzKyQE4SZmRVygjAzs0IepDajuvPbmDUKJwgb9qo9v41Zoyi1i0nSTEntkjokzSuo31vSd1P9ryRNytXNT+XtkmaUGacNb9We38asUZSWICQ1AdcBpwBTgTmSpvZodi7wTEQcAVwNXJm2nQrMBt4AzAT+Oe3PbNBVe34bs0ZR5hnEcUBHRKyLiJeARcDpPdqcDvxren0bcKIkpfJFEfFiRPwO6Ej7Mxt01Z7fxqxRlJkgxgPrc+sbUllhm4jYCjwLHNjHbZF0nqQ2SW0bN24cxNBtOKn2/DZmjaKhL3ONiBsiohIRlZaWllqHYw1q1vTxXH7GUYwf04yA8WOaufyMozxAbcNemVcxdQITc+sTUllRmw2S9gJGA0/3cVuzQVPN+W3MGkWZZxDLgCmSJksaSTbovLRHm6XAOen1mcDdERGpfHa6ymkyMAW4r8RYzcysh9LOICJiq6QLgFagCbgxIlZLWgC0RcRS4BvAzZI6gE1kSYTUbjGwBtgKfDIithW+kZmZlULZH+yNr1KpRFtbW63DMDNrKJKWR0SlqK6hB6nNzKw8ThBmZlbICcLMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkVcoIwM7NCThBmZlZoyEy1IWkj8Git46gzY4Gnah1EHfJx2ZmPSbHhcFwOjYjC5yUMmQRhO5PU1tscK8OZj8vOfEyKDffj4i4mMzMr5ARhZmaFnCCGthtqHUCd8nHZmY9JsWF9XDwGYWZmhXwGYWZmhZwgzMyskBNEA5D0iKRVkh6Q1JbKDpB0p6SH08/9U7kkXSupQ9JKScfk9nNOav+wpHNy5W9K++9I26r6n3L3JN0o6UlJD+XKSj8Ovb1HvejluFwmqTP9zjwg6T25uvnpM7ZLmpErn5nKOiTNy5VPlvSrVP5dSSNT+d5pvSPVT6rOJ949SRMl3SNpjaTVkv42lQ/735d+iQgvdb4AjwBje5RdBcxLr+cBV6bX7wF+DAh4C/CrVH4AsC793D+93j/V3ZfaKm17Sq0/cy/H4QTgGOChah6H3t6jXpZejstlwKcL2k4FHgT2BiYDa4GmtKwFDgNGpjZT0zaLgdnp9VeBj6fXnwC+ml7PBr5b62OR+5wHA8ek1/sBv02ffdj/vvTrONY6AC99+EcqThDtwMHp9cFAe3p9PTCnZztgDnB9rvz6VHYw8Jtc+Q7t6m0BJvX4Iiz9OPT2HvW0FByX3hLEfGB+br0V+Mu0tPZsl778ngL2SuUvt+veNr3eK7VTrY9FL8fn+8C7/fvSv8VdTI0hgJ9IWi7pvFR2UEQ8kV7/HjgovR4PrM9tuyGV7ap8Q0F5o6jGcejtPerdBam75MZcN0d/j8uBwOaI2NqjfId9pfpnU/u6krq+pgO/wr8v/eIE0RjeFhHHAKcAn5R0Qr4ysj9Vhv31ytU4Dg10rP8FOBw4GngC+GJtw6kNSfsCtwMXRcRz+Tr/vuyeE0QDiIjO9PNJ4HvAccAfJB0MkH4+mZp3AhNzm09IZbsqn1BQ3iiqcRx6e4+6FRF/iIhtEbEd+BrZ7wz0/7g8DYyRtFeP8h32lepHp/Z1QdIIsuTwnYi4IxX796UfnCDqnKTXSNqv+zVwMvAQsBTovqLiHLI+VlL5B9JVGW8Bnk2nu63AyZL2T90NJ5P1JT8BPCfpLekqjA/k9tUIqnEcenuPutX9BZX8FdnvDGSfZXa6AmkyMIVssHUZMCVdsTSSbNB5afoL+B7gzLR9z2PcfVzOBO5O7Wsu/Rt+A/h1RHwpV+Xfl/6o9SCIl10vZFeVPJiW1cBnU/mBwF3Aw8B/AAekcgHXkV2Rsgqo5Pb1YaAjLR/KlVfIvkDWAv9E/Q40/htZd8kWsj7fc6txHHp7j3pZejkuN6fPvZLsC+vgXPvPps/YTu6KNbIreX6b6j7b43fwvnS8bgX2TuX7pPWOVH9YrY9FLua3kXXtrAQeSMt7/PvSv8VTbZiZWSF3MZmZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkVcoKwuiApJH0xt/5pSZcN0r5vknTm7lvu8fu8X9KvJd3To3ySpK40q+oaSV+VVPP/e5LGSPpEreOw+lXzX1Kz5EXgDEljax1IXu4O4r44F/hoRLyzoG5tRBwNTCObVXRWH99fJSaTMWQzsvZZyfFYnfE/tNWLrWTP//0/PSt6ngFIeiH9fIekn0n6vqR1kq6Q9DeS7kvz9B+e281Jktok/VbS+9L2TZIWSlqWJrX7WG6//ylpKbCmIJ45af8PSboylV1KdnPWNyQt7O1DRjap3X8BR0jaV9Jdku5P+zs97WuSsucyfIvsRqyJkv4lxb9a0udzsTwi6fJ0dtIm6RhJrZLWSjo/125u7nN2b38FcHjadmFv7XqJ56b0+VdJ2unfzIaIWt+p58VLRAC8AIwim9p8NPBp4LJUdxNwZr5t+vkOYDPZlMp7k82F8/lU97fANbnt/x/ZH0RTyO423gc4D7gktdkbaCN7RsI7gD8CkwviHAc8BrSQTXF9NzAr1f2U3B24uW0mkabiBl5NNq3FKWn7Ual8LNmdukrttwNvye2j+47fpvQ+09L6I7zyfIarye4c3i/F94dUfjJZ8lU6Bj8ke4bEy3H1od3L8QBvAu7MbTem1r8/XspZ+nP6bFaqiHgu/ZV6IdDVx82WRZpaWdJa4CepfBWQ7+pZHNnEdQ9LWgf8N7IvxGm5s5PRZAnkJeC+iPhdwfsdC/w0Ijam9/wO2Zfokt3EebikB8imf/h+RPxY2WRy/6Bsdt7tZNNFd08N/WhE3Jvb/ixlU73vRZYQp5IlA8im0uj+zPtGxPPA85JelDQmfc6TgRWp3b7pcz7WI8ZdtcvHsw44TNJXgB/xyjG3IcYJwurNNcD9wDdzZVtJ3aGp/3tkru7F3OvtufXt7Pj73XNOmSD7S/lTEdGar5D0DrIziMHUPQaR9zdkf+m/KSK2SHqE7MyG/PunSfU+DRwbEc9IuinXDnb8zD2Px15kn/PyiLg+/+ba+RGhu2r3cjwphv8OzADOB84im6/IhhiPQVhdiYhNZI+4PDdX/AhZtwbAacCIAez6/ZJelcYlDiObqK4V+Hj6Sx5Jr1M2Y+6u3Ae8XdJYSU1kTxL72QDigeyM5cmUHN4JHNpLu1FkX9DPSjqIrHuqP1qBDyt7NgKSxkv6C+B5su6o3bXbQbqQ4FURcTtwCdnjTm0I8hmE1aMvAhfk1r8GfF/Sg2RjCQP56/4xsi/3UcD5EfFnSV8n61+/XyXSGH0AAACPSURBVJKAjezm6qKIeELSPLIpsAX8KCIGOp3zd4AfSFpFNv7xm17e80FJK1L9euAX/XmTiPiJpNcDv8w+Ji8AZ0fEWkm/kPQQ8OOImFvUDtjWY5fjgW/mrmaa3594rHF4NlczMyvkLiYzMyvkBGFmZoWcIMzMrJAThJmZFXKCMDOzQk4QZmZWyAnCzMwK/X+ceObAg67DOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "plt.scatter([m1,m2,m3,m4,m5,m6,m7,m8,m9,m10],train_loss_list)\n",
    "plt.scatter([m1,m2,m3,m4,m5,m6,m7,m8,m9,m10],test_loss_list)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Parameters');\n",
    "\n",
    "plt.pause(0.1)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.scatter([m1,m2,m3,m4,m5,m6,m7,m8,m9,m10],train_acc_list)\n",
    "plt.scatter([m1,m2,m3,m4,m5,m6,m7,m8,m9,m10],test_acc_list)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Parameters');\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
